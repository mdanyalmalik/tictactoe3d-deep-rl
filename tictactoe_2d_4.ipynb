{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [[\" \" for _ in range(4)] for _ in range(4)]\n",
    "        self.current_player = -1\n",
    "\n",
    "\n",
    "    def check_draw(self):\n",
    "        for row in self.board:\n",
    "            if \" \" in row:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def print_board(self):\n",
    "        # Prints a GUI-like representation of the board\n",
    "        print(\"┌───┬───┬───┬───┐\")\n",
    "        for i, row in enumerate(self.board):\n",
    "            print(\"│ \" + \" │ \".join(row) + \" │\")\n",
    "            if i < 3:\n",
    "                print(\"├───┼───┼───┼───┤\")\n",
    "        print(\"└───┴───┴───┴───┘\")\n",
    "\n",
    "    def check_winner(self, player):\n",
    "        for row in self.board:\n",
    "            if all([cell == player for cell in row]):\n",
    "                return True\n",
    "        for col in range(4):\n",
    "            if all([self.board[row][col] == player for row in range(4)]):\n",
    "                return True\n",
    "        if all([self.board[i][i] == player for i in range(4)]) or all(\n",
    "            [self.board[i][3 - i] == player for i in range(4)]\n",
    "        ):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def step(self, state):\n",
    "        '''\n",
    "        Returns (new_state, current_player, done, reward)\n",
    "        '''\n",
    "        row = int(state / 4)\n",
    "        col = int(state % 4)\n",
    "\n",
    "        current_player_symbol = \" \"\n",
    "        if self.current_player == -1:\n",
    "            current_player_symbol = \"X\"\n",
    "        else:\n",
    "            current_player_symbol = \"O\"\n",
    "\n",
    "        if self.board[row][col] == \" \":\n",
    "            self.board[row][col] = current_player_symbol\n",
    "\n",
    "        if self.check_winner(\"O\"):\n",
    "            return self.board, self.current_player, True, -1\n",
    "        elif self.check_winner(\"X\"):\n",
    "            return self.board, self.current_player, True, 1\n",
    "        elif self.check_draw():\n",
    "            return self.board, self.current_player, True, 0\n",
    "\n",
    "        self.current_player *= -1\n",
    "\n",
    "        return self.board, self.current_player, False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialized as a random policy for player 1\n",
    "\n",
    "def policy_player1(board):\n",
    "\n",
    "    possible_actions = []\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if board[i][j] == \" \":\n",
    "                possible_actions.append(i*4 + j)\n",
    "\n",
    "\n",
    "    return random.choice(possible_actions)\n",
    "\n",
    "# Initialized as a random policy for player 2\n",
    "def policy_player2(board):\n",
    "\n",
    "    possible_actions = []\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if board[i][j] == \" \":\n",
    "                possible_actions.append(i*4 + j)\n",
    "\n",
    "    return random.choice(possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9716664, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class State(Enum):\n",
    "    X = -1\n",
    "    O = 1\n",
    "    DRAW = 0\n",
    "    NOT_TERMINAL = 2\n",
    "\n",
    "def has_player_won(board, player):\n",
    "\n",
    "    # List down all win conditions for a 3x3 board\n",
    "    win_conditions = [\n",
    "            (0, 1, 2, 3), (4, 5, 6, 7), (8, 9, 10, 11), (12, 13, 14, 15),   # horizontal\n",
    "            (0, 4, 8, 12), (1, 5, 9, 13), (2, 6, 10, 14), (3, 7, 11, 15),    # vertical\n",
    "            (0, 5, 10, 15), (3, 6, 9, 12)                                   # diagonal\n",
    "    ]\n",
    "\n",
    "    for condition in win_conditions:\n",
    "        if all(board[i] == player for i in condition):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def is_board_terminal(board):\n",
    "    '''\n",
    "    Checks if the board is in a terminal state\n",
    "    '''\n",
    "    # Check if X or O have won\n",
    "    if has_player_won(board, State.X.value):\n",
    "        return State.X.value\n",
    "    elif has_player_won(board, State.O.value):\n",
    "        return State.O.value\n",
    "    \n",
    "    # If the board is full, but there's no win\n",
    "    if 0 not in board:\n",
    "        return State.DRAW.value\n",
    "    \n",
    "    # If the board is not full\n",
    "    return State.NOT_TERMINAL.value\n",
    "\n",
    "def reward_function(board):\n",
    "    '''\n",
    "    Returns the reward for the current board\n",
    "    '''\n",
    "\n",
    "    state_value = is_board_terminal(board)\n",
    "\n",
    "    if state_value != State.NOT_TERMINAL.value:\n",
    "        return state_value # could be a winning condition or a terminal draw\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def check_invalid_after_win(board):\n",
    "    '''\n",
    "    A utility function that checks if the board is in an invalid state after a win\n",
    "    This can happen because X won and then O played again\n",
    "    There are two cases to check if a winning satate is valid:\n",
    "    1. If X has won, then there should be one more X than O\n",
    "    2. If O has won, then there should be the same number of X and O\n",
    "    3. If the game is a draw, then there should be one more X than O\n",
    "    '''\n",
    "    # Check if there is a winner\n",
    "    has_x_won = has_player_won(board, State.X.value)\n",
    "    has_o_won = has_player_won(board, State.O.value)\n",
    "    state_value = is_board_terminal(board)\n",
    "\n",
    "    # It is not possible that both have won\n",
    "    if has_x_won and has_o_won:\n",
    "        return True\n",
    "\n",
    "    # If only X has won\n",
    "    elif has_x_won:\n",
    "        # Check if there is one more X than O\n",
    "        if sum(board) == -1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    # If only O has won\n",
    "    elif has_o_won:\n",
    "        # Check if there is the same number of X and O\n",
    "        if sum(board) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    # If there is a draw then there should be one more X than O\n",
    "    elif state_value == State.DRAW.value:\n",
    "        # Should be one more X than O\n",
    "        if sum(board) == -1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    else:\n",
    "        # If there is no winner, then the board is valid\n",
    "        return False\n",
    "\n",
    "def generate_boards(board, index=0):\n",
    "    all_boards = []\n",
    "\n",
    "    # If the board is complete, add it to the list\n",
    "    if index == len(board):\n",
    "\n",
    "        # Check if the sum of the board is -1 or 0\n",
    "        valid_sum = (sum(board) in [-1, 0])\n",
    "        valid_win = (not check_invalid_after_win(board))\n",
    "        if valid_sum and valid_win:\n",
    "            all_boards.append(board.copy())\n",
    "        return all_boards\n",
    "\n",
    "    # Try placing X, O, or leaving the spot empty\n",
    "    for value in [-1, 0, 1]:\n",
    "        board[index] = value\n",
    "        all_boards.extend(generate_boards(board, index + 1))\n",
    "\n",
    "    return all_boards\n",
    "\n",
    "# states = generate_boards([0 for _ in range(16)])\n",
    "# states = list(set([tuple(board) for board in states]))\n",
    "# states = [list(board) for board in states]\n",
    "\n",
    "states = np.load(\"boards.npy\")\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(state):\n",
    "    '''\n",
    "    Return possible actions\n",
    "    '''\n",
    "    return [i for i, p in enumerate(state) if p == 0]    \n",
    "\n",
    "def get_reward(state):\n",
    "    '''\n",
    "    Return reward for state\n",
    "    '''\n",
    "    reward = is_board_terminal(state)\n",
    "    reward = 0 if reward == State.NOT_TERMINAL.value else reward\n",
    "\n",
    "    return reward\n",
    "\n",
    "def get_turn(state):\n",
    "    '''\n",
    "    Return whose turn it is\n",
    "    '''\n",
    "    # -1 is X and 1 is O\n",
    "    # If the sum is -1, then it is O's turn\n",
    "    return 1 if sum(state) else -1\n",
    "\n",
    "def Qlearning(states, num_episodes=10000, gamma=0.99, alpha=0.5, epsilon=1):\n",
    "    '''\n",
    "    Performs Value Iteration and returns the final Value table, Q-table and policies\n",
    "    '''\n",
    "\n",
    "    # Initialise tables\n",
    "    q_table = {tuple(state): {action: 0 for action in get_actions(state) if is_board_terminal(state) == State.NOT_TERMINAL.value} for state in states}\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        done = False        \n",
    "\n",
    "        # Randomly select a state\n",
    "        state = random.choice(states)\n",
    "        to_play = get_turn(state)\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # Sample an action using epsilon-greedy\n",
    "            if np.random().random() < epsilon:\n",
    "                action = random.choice(get_actions(state))\n",
    "            else:\n",
    "                action = max(q_table[tuple(state)], key=q_table[tuple(state)].get)\n",
    "\n",
    "            # Take the action\n",
    "            next_state = state.copy()\n",
    "            next_state[action] = to_play\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# v_table, q_table, policy = value_iteration(states, turns, max_iterations=100, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(policy_player1, policy_player2):\n",
    "    tictactoe = TicTacToe()\n",
    "\n",
    "    terminated = 0\n",
    "    board = [[\" \" for _ in range(4)] for _ in range(4)]\n",
    "\n",
    "    for i in range(8):\n",
    "        for turn in [-1, 1]:\n",
    "            action = 0\n",
    "            if turn == -1:\n",
    "                action = policy_player1(board)\n",
    "            else:\n",
    "                action = policy_player2(board)\n",
    "\n",
    "            board, player, terminated, reward = tictactoe.step(action)\n",
    "\n",
    "            # Uncomment this if you want to see the board\n",
    "            tictactoe.print_board()\n",
    "\n",
    "            if terminated:\n",
    "                break\n",
    "\n",
    "    return -1*reward # This is the player who won\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_alternating_games(games=10):\n",
    "    results = []\n",
    "    for i in range(games):\n",
    "        for j in range(2):\n",
    "            if j==0:\n",
    "                winner = play_one_game(policy_player1, policy_player2)\n",
    "\n",
    "                match winner:\n",
    "                    case -1:\n",
    "                        results.append(1)\n",
    "                    case 1:\n",
    "                        results.append(2)\n",
    "                    case 0:\n",
    "                        results.append(0)\n",
    "\n",
    "            if j==1:\n",
    "                winner = play_one_game(policy_player2, policy_player1)\n",
    "\n",
    "                match winner:\n",
    "                    case -1:\n",
    "                        results.append(2)\n",
    "                    case 1:\n",
    "                        results.append(1)\n",
    "                    case 0:\n",
    "                        results.append(0)\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draws:  845\n",
      "Player 1 Wins: 577\n",
      "Player 2 Wins: 578\n"
     ]
    }
   ],
   "source": [
    "results = run_alternating_games(1000)\n",
    "print(\"Draws: \", results.count(0))\n",
    "print(\"Player 1 Wins:\", results.count(1))\n",
    "print(\"Player 2 Wins:\", results.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created two functions that randomly select any action from the available actions from the board. Your team will have to create such a function that outputs the optimal action given a particular board state. This a similar kind of code I will be using on competition day when your function will play against an opponent's functions for perhaps a 1000 games. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will pass your and your opponent's function into the run alternating games function for maybe 1000 games to see who won more games. That person will be the winner of the match. I think it's a reliable method to compare policies. Run them by each for 1000s of games and see what policy wins the most games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to solve this part using **Q Learning**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
